{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part1-MAA-TX22-Redistricting-Workshop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drscook/MathVGerrmandering_CMAT_2022/blob/main/Part1_MAA_TX22_Redistricting_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m86T9tALe-6P"
      },
      "source": [
        "# Mathematical Association of America - Texas Section\n",
        "# 2022 Annual Meeting\n",
        "# Workshop on Mathematical Tools to Fight Gerrymandering\n",
        "# Part I - Ensemble Analysis with GerryChain\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Event Information"
      ],
      "metadata": {
        "id": "8maVdcySdaeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time, Date, & Location\n",
        "*7:00pm - 9:00pm*  \n",
        "*March 31*  \n",
        "*Gateway 42*  \n",
        "*UNT Gateway Center*  \n",
        "*Denton, TX*  \n",
        "\n",
        "\n",
        "**Link to this Jupyter Notebook: https://tinyurl.com/gerrychain** \n",
        "\n",
        "Zoom link: https://unt.zoom.us/j/83519091082\n",
        "\n",
        "GitHub Repo: https://github.com/drscook/Redistricting_Workshop_MAA_TX_2022\n",
        "\n",
        "Video: https://youtu.be/a0zgVTTcFiQ"
      ],
      "metadata": {
        "id": "Wh17wN2m28hO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjoeV96M0GH8"
      },
      "source": [
        "### Contributors\n",
        "\n",
        "Workshop Facilitators:\n",
        "- Dr. Scott Cook<sup>4</sup>\n",
        "- Jaryd Domine<sup>3</sup>\n",
        "- Cody Drolet<sup>4</sup>\n",
        "- Dr. Will Hager<sup>5</sup>\n",
        "- Mason McCallum<sup>3</sup>\n",
        "- Dr. Betseygail Rand<sup>5</sup>\n",
        "- Vianey Rangel<sup>4</sup>\n",
        "\n",
        "Part I notebook contributors:\n",
        "- Dr. Scott Cook<sup>4</sup>\n",
        "- Diana Dinh-Andrus<sup>3</sup>\n",
        "- Dr. Will Hager<sup>5</sup>\n",
        "- Anthony Pizzimenti<sup>2</sup>\n",
        "- Casey Sutton<sup>4</sup>\n",
        "- Maria Tovar<sup>4</sup>\n",
        "- Preston Ward<sup>4</sup>\n",
        "\n",
        "Part II notebook contributors:\n",
        "- Dr. Scott Cook<sup>4</sup>\n",
        "\n",
        "Special Thanks:\n",
        "- Metric Geometry & Gerrymandering Group\n",
        "    - Dr. Moon Duchin<sup>6</sup>\n",
        "- Math For Unbiased Maps Texas\n",
        "    - Dr. Andrea Barreiro<sup>3</sup>\n",
        "    - Dr. Matt Lockard<sup>3</sup>\n",
        "    - Dr. Scott Norris<sup>3</sup>\n",
        "    - Robert Meyers\n",
        "    - Dr. Dustin Potter<sup>1</sup>\n",
        "    - Dr. Brandi Stigler<sup>3</sup>\n",
        "\n",
        "\n",
        "<sup>1</sup>Collin College, <sup>2</sup>Iowa State Univ, <sup>3</sup>Southern Methodist Univ, <sup>4</sup>Tarleton State Univ, <sup>5</sup>Texas Lutheran State Univ, <sup>6</sup>Tufts Univ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Workshop Agenda\n",
        "\n",
        "Ensemble analysis of electorial districting plans consists of several steps:\n",
        "1. Get data - Retrieve, prepare, and combine geographic, demographic, and electoral data and assemble into a single dataset\n",
        "2. Generate ensemble - Feed this dataset into tools like GerryChain to generate an ensemble of districting plans\n",
        "3. Analyze - Statistically compare a proposed/enacted plan against the ensemble\n",
        "\n",
        "Part I of this workshop focuses on steps 2 & 3 and assumes step 1 has already been completed.  Steps 2 & 3 are more interesting and satisfying mathematically and politically.  Step 1 is more tedious and requires more complex code, but is essential if you aim to do something beyond the scope of the dataset we provided.\n",
        "\n",
        "Part II focuses on step 1 - retrieving, preparing, and combining data.  We will probably not discuss every line of code, but we'll hit as many highlights as time allows."
      ],
      "metadata": {
        "id": "0Bh7s_DPTcmV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y-_KS2Vfa0s"
      },
      "source": [
        "### Applications\n",
        "\n",
        " \n",
        "  - Google Colab - What you are seeing right now.  Free, cloud based Python distribution from Google.  Like Google docs for Python.  Side note - allows you to attach GPU or TPU devices too for parallel computing (though we won't use that in this workshop)\n",
        "  - Pandas - Data analysis package for Python.  We make use of its dataframes in this talk.\n",
        "    - [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
        "  - GeoPandas - A Python package that allows the addition of geographic information to Pandas dataframes.\n",
        "    - [Geopandas Documentation](https://geopandas.org/en/stable/docs.html)\n",
        "  - Networkx - A Python package that creates, edits, and analyzes graphs.\n",
        "    - [Networkx Documentation](https://networkx.github.io/)  \n",
        "  - GerryChain - Python package to implement mathematical tools for gerrymandering.  Specifically designed to run Markov Chain Monte Carlo (MCMC) methods with a wide range of metrics.  Developed during the summer 2018 [Voting Rights Data Institute](https://sites.tufts.edu/vrdi/).\n",
        "    - [GerryChain Documentation](https://gerrychain.readthedocs.io/en/latest/)\n",
        "  -GerryChainJulia - Gerrychain in a Julia package.  The Julia implementation of Gerrychain tends to run faster than the Python implementation.\n",
        "    - [GerryChainJulia Documentation](https://mggg.github.io/GerryChainJulia/stable/) \n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 0 - Before You Start\n",
        "\n",
        "**Make a personal copy of this Colab notebook in your Google Drive so you can add, edit, take notes, comment, execute code, etc.  File â†’ Save a copy in Drive**\n",
        " "
      ],
      "metadata": {
        "id": "8rSh7-yLyinN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McP-AE_Ifum2"
      },
      "source": [
        "---\n",
        "## 1 - Install Gerrychain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p28T18grrK-z"
      },
      "source": [
        "In the following section we install the GerryChain library and import the functions we will need to run MCMC methods.  This package will create a collection of partitions against which we can compare real world partitions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPKOca8wIbQQ"
      },
      "outputs": [],
      "source": [
        "#  This takes 3 minutes. You will receive an error message \"Your session crashed \n",
        "#  for an unknown reason.\"  This happens because condacolab restarts the kernel \n",
        "#  of this worksheet.   \n",
        "\n",
        "# installs condacolab, which allows installation of conda\n",
        "! pip install -q condacolab  \n",
        "\n",
        "# installs conda, which allows installation of mamba\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try this first - its much faster if it works\n",
        "! mamba install -q -y -c conda-forge gerrychain geopandas\n",
        "\n",
        "# if that fails, use the slower\n",
        "# ! conda install -q -y -c conda-forge gerrychain geopandas\n",
        "\n",
        "from IPython import get_ipython\n",
        "get_ipython().kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "uyaY2IcjrVpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2 - Create GeoDataFrame from Imported Data"
      ],
      "metadata": {
        "id": "MjgjhZPwUjqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a - Download a Data File and Load It Into a GeoDataFrame\n",
        "\n",
        "The GeoJSON file downloaded in the cell below can also be found at the following link:  [Texas VTD Dataset](https://drive.google.com/file/d/1i-wOVyGf2RnQJSpCxDKlVBoJjVm-Pskq/view?usp=sharing)."
      ],
      "metadata": {
        "id": "spAv0-wWmY3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  This takes 2 minutes.\n",
        "\n",
        "#  Installs a downloader for Google Drive files.\n",
        "!pip install gdown \n",
        "\n",
        "#  Downloads a .zip file from Google Drive.  Saves to Colab's local disk.  This \n",
        "#  will be lost when the runtime is restarted.  If you wish to keep it, download \n",
        "#  from the 'Files' tab on the left edge of the screen.\n",
        "!gdown \"1i-wOVyGf2RnQJSpCxDKlVBoJjVm-Pskq\" -O \"VTD-Data.zip\"  #\n",
        "\n",
        "#  Unzips the downloaded file.\n",
        "!unzip \"/content/VTD-Data.zip\""
      ],
      "metadata": {
        "id": "5u2xPKDqdyjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  GeoPandas allows us to work with dataframes containing geometric data.\n",
        "import geopandas as gpd\n",
        "\n",
        "#  Creates a geodataframe from the unzipped file.\n",
        "gdf = gpd.read_file('/content/VTD_Data (1).geojson')"
      ],
      "metadata": {
        "id": "SVkUwseN29y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that GeoPandas can create GeoDataFrames from a variety of different filetypes.  See the [documentation](https://geopandas.org/en/stable/docs/user_guide/io.html) for more details."
      ],
      "metadata": {
        "id": "r0wfnSRa4tND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b - Check the GeoDataFrame\n",
        "\n",
        "Let's take a look at it in table form."
      ],
      "metadata": {
        "id": "SgBzoAWMdSWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf"
      ],
      "metadata": {
        "id": "KnWJpL1ddSKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the GeoDataFrame's geometries.  You should see Texas after running the cell."
      ],
      "metadata": {
        "id": "6uasg-Wdc5ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.plot(column=\"county\", figsize = (8,8), cmap = 'tab20')"
      ],
      "metadata": {
        "id": "tifsivVs_Q2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Optional - Using GeoDataFrames\n",
        "\n",
        "There are many ways to read and view the data in our GeoDataFrame."
      ],
      "metadata": {
        "id": "AT3InuSC_dPh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quick Overviews.\n",
        "We can get a quick look at the top or bottom of the table."
      ],
      "metadata": {
        "id": "OiLTg0gD6YBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.head(3)"
      ],
      "metadata": {
        "id": "mSAisTog_roO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.tail(4)"
      ],
      "metadata": {
        "id": "vSiKBa-P3X3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calling Entries from DataFrames."
      ],
      "metadata": {
        "id": "lYjnV7V96cMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can select an entry using its index and column name..."
      ],
      "metadata": {
        "id": "4qJNnfXZ_yN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.loc[9006,'county']"
      ],
      "metadata": {
        "id": "-fg_LF4y3Xs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.loc[9006,'geometry']"
      ],
      "metadata": {
        "id": "kauZmK0y3wYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...or by row and column number.  Note that we start counting at zero."
      ],
      "metadata": {
        "id": "iaCxWnINAFWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.iloc[9006,2]"
      ],
      "metadata": {
        "id": "logjAM2Y3Xfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.iloc[9006,858]"
      ],
      "metadata": {
        "id": "nIr5JyEo3t4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieving Data from Columns."
      ],
      "metadata": {
        "id": "Ck5fBE206Sek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf['county']"
      ],
      "metadata": {
        "id": "snF05c8h51El"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf['total_pop']"
      ],
      "metadata": {
        "id": "fmOTnt1P6DpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieving Data from Rows."
      ],
      "metadata": {
        "id": "PTC6G7zc6r9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.loc[3]"
      ],
      "metadata": {
        "id": "rnOFA9EO6QJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.loc[8]"
      ],
      "metadata": {
        "id": "CMBSltCo62k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating SubDataFrames"
      ],
      "metadata": {
        "id": "beO8U6rY7-CE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can create a smaller dataframe from particular rows and columns..."
      ],
      "metadata": {
        "id": "AeUCav1o9p3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.loc[[2,6],['county','total_pop']]"
      ],
      "metadata": {
        "id": "8hlanhpi62cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or we can include a range of rows and columns."
      ],
      "metadata": {
        "id": "KSuewID08FP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.loc[2:6, 'county':'total_pop']"
      ],
      "metadata": {
        "id": "AmbHpOsr62VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can even filter the dataframe."
      ],
      "metadata": {
        "id": "gXC8KhTm-Cgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf[gdf['total_pop'] >= 20000]"
      ],
      "metadata": {
        "id": "2NnhVcnC-gOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf[gdf['county'].isin(['Dallas', 'Denton', 'Tarrant'])]"
      ],
      "metadata": {
        "id": "UX-vB-2X4BEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting GeoDataFrames"
      ],
      "metadata": {
        "id": "3DTY6iLQAzm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The geometries of GeoDataFrames can be plotted."
      ],
      "metadata": {
        "id": "PpvBtuJK-6VT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.plot()"
      ],
      "metadata": {
        "id": "_SL-iDz7eJEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.plot(column = 'county')"
      ],
      "metadata": {
        "id": "gTvRZURsBHhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.plot(column = 'cd')"
      ],
      "metadata": {
        "id": "1jLg5VW8eOWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtered GeoDataFrames too!"
      ],
      "metadata": {
        "id": "beyWg0glBZOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf[gdf['county'].isin(['Dallas', 'Denton', 'Tarrant'])].plot(column = 'county')"
      ],
      "metadata": {
        "id": "KT1g5JJF4A9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving a GeoDataFrame\n",
        "\n",
        "You can save your GeoDataFrame as a GeoJSON file.  This will take some time for a large dataframe like ours.  **Note that Colab's file folders do not provide storage after the runtime ends.  You must either store a file on Google Drive or download it to your local machine to keep it.**  "
      ],
      "metadata": {
        "id": "GiGCWOWUAkBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This takes 30+ minutes for our dataframe.\n",
        "%%script false  <--- This line prevents this cell from running.  Remove to use cell.\n",
        "\n",
        "filepath = \"\"  #Write destination filepath string here.  End with .geojson\n",
        "gdf.to_file(filepath, driver='GeoJSON')"
      ],
      "metadata": {
        "id": "hEQFXL6v4A0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3 - Run GerryChain on Graph\n",
        "\n",
        "Gerrychain creates a large set of partitions on a graph. Texas will be represented as a graph, and each partition represents a possible way to break Texas into single member voting districts.\n",
        "\n",
        "First we import various commands that Gerrychain uses."
      ],
      "metadata": {
        "id": "Zp5k0dr2U8kH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gerrychain import Graph, Partition, Election, MarkovChain, GeographicPartition\n",
        "from gerrychain.updaters import Tally, cut_edges\n",
        "from gerrychain.constraints import single_flip_contiguous, contiguous\n",
        "from gerrychain import constraints\n",
        "from gerrychain.proposals import propose_random_flip, recom\n",
        "from gerrychain.accept import always_accept\n",
        "from functools import partial"
      ],
      "metadata": {
        "id": "KaPguxJrlQVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a - Creating a graph of our geometries using GerryChain.  \n",
        "\n",
        "Here we are converting Texas into a graph. The vertex set of this graph will be our Voting Tabulation Districts, or VTDs. Edges will connect VTDs when they share a boundary."
      ],
      "metadata": {
        "id": "22okc7EiBqUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  You will get some error messages here.  All is well.  We will talk about this.\n",
        "graph = Graph.from_geodataframe(gdf)"
      ],
      "metadata": {
        "id": "CfR_P4MML4e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional - Prepping the graph for GerryChain\n",
        "\n",
        "Some graphs may not satisfy the constraints you wish to use in GerryChain.  For instance, a graph may not be connected and so cause a violation of GerryChains \"contiguous\" constraint for its districts.  One can interact and edit the graph using the networkx package until it is ready for use in GerryChain.  "
      ],
      "metadata": {
        "id": "84y9O7H9aKj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "nx.is_connected(graph)"
      ],
      "metadata": {
        "id": "I80LYDc0vJYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH0DwDMCfuYB"
      },
      "source": [
        "\n",
        "### b - Create an Initial Partition for Gerrychain\n",
        "\n",
        "Gerrychain generates the set of partitions by taking a random walk through the statespace of valid partitions. This step creates the seed for the random walk.  The seed we are currently using is the U.S. Congressional District map of Texas (117th Congress), which has 36 single-member districts as determined by apportionment following the 2010 census.  Texas will soon have 38 districts, according to 2020 census apportionment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IcNg0nFpyHp"
      },
      "source": [
        "initial_partition = Partition(\n",
        "    graph,\n",
        "    assignment=\"cd\",\n",
        "    updaters={\n",
        "        \"cut_edges\": cut_edges,\n",
        "        \"population\": Tally(\"total_pop\", alias=\"population\")\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OrbnqSkfuWN"
      },
      "source": [
        "\n",
        "### c - Use Gerrychain to Generate a Collection of District Plans."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by defining some quantities that GerryChain will use to create its collection of partitions."
      ],
      "metadata": {
        "id": "IbDuHTeWDPbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tallies the total population of the graph for later use.\n",
        "total_pop = 0\n",
        "for node in graph.nodes:\n",
        "  total_pop+=graph.nodes[node]['total_pop']\n",
        "\n",
        "# Creates a list of district names for later use.\n",
        "districts = []\n",
        "for node in graph.nodes:\n",
        "  vtd_district = graph.nodes[node]['cd']\n",
        "  if vtd_district not in districts:\n",
        "    districts.append(vtd_district)\n",
        "num_districts = len(districts)\n",
        "\n",
        "# Defines the target population per district.\n",
        "pop_target = int(total_pop/ num_districts)\n",
        "\n",
        "# Defines the allowable deviation from the target population.\n",
        "pop_constraint = constraints.within_percent_of_ideal_population(initial_partition, 0.35, pop_key = 'population' )\n",
        "\n",
        "# Tells GerryChain how to change a partition to create a new partition.\n",
        "proposal = partial(recom, pop_col='total_pop', pop_target=pop_target, epsilon=.1, node_repeats=10)"
      ],
      "metadata": {
        "id": "tXfmb86qP8pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now ask GerryChain to create the collection of partitions."
      ],
      "metadata": {
        "id": "xZGBt37aDY3w"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcVcAtGoqXYH"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "total_steps = 100   # Write the total number of partitions you wish to generate.\n",
        "\n",
        "chain = MarkovChain(\n",
        "    proposal=proposal, # Tells GerryChain how to create a new partition.\n",
        "    constraints=[contiguous,pop_constraint],  #  New partitions that do not meet the constraints are discarded.\n",
        "    accept=always_accept,\n",
        "    initial_state=initial_partition,\n",
        "    total_steps=total_steps\n",
        ")\n",
        "partition_counter = 0\n",
        "for partition in chain:  # This loop writes the each VTD's assigned district for each partition in the chain.\n",
        "    for vtd in gdf.index:\n",
        "      gdf.loc[vtd,'cd_'+str(partition_counter)] = partition.assignment[vtd]\n",
        "    clear_output()\n",
        "    print('Partition '+str(partition_counter) + ' of '+ str(total_steps-1) + ' recorded to GeoDataFrame.')\n",
        "    partition_counter+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See the partitions recorded in the final columns of the table?"
      ],
      "metadata": {
        "id": "CLioqCAHFlMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.head(3)"
      ],
      "metadata": {
        "id": "PSbxjHNoFrVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following two plots, compare our initial partition (U.S. Congressional Districts) to the partition 100 steps down the chain."
      ],
      "metadata": {
        "id": "FRhXdZutFN-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.plot(column=\"cd\", figsize = (12,12), cmap = 'tab20')"
      ],
      "metadata": {
        "id": "jGPP5XVFkKNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.plot(column=\"cd_99\", figsize = (12,12), cmap = 'tab20')"
      ],
      "metadata": {
        "id": "HnjCWI5DLY7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl8n-AZdfuSN"
      },
      "source": [
        "---\n",
        "## 4 - Extract and Use Data from Partitions Recorded on the GeoDataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time to run an experiment.  There are a few examples below that you are welcome to use or edit.  For your reference, here are the available columns in the GeoDataFrame."
      ],
      "metadata": {
        "id": "te1r9QN_xrrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in gdf.columns:\n",
        "  print(col)"
      ],
      "metadata": {
        "id": "C-5J6-K3x0pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example A - Polsby-Popper\n",
        "\n",
        "We can calculate the Polsby-Popper value over all districts in a partition.  Note that for any given polygon..."
      ],
      "metadata": {
        "id": "XajkszedsdYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.loc[0,'geometry']"
      ],
      "metadata": {
        "id": "481pCeyS2bGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...we can calculate its area..."
      ],
      "metadata": {
        "id": "-UkwDwoM4Z78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.loc[0,'geometry'].area"
      ],
      "metadata": {
        "id": "-N9TLgD24Yuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "... and its perimeter."
      ],
      "metadata": {
        "id": "oCrRcykf4lqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.loc[0,'geometry'].length"
      ],
      "metadata": {
        "id": "xitzuL3O4iA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means we can calculate its Polsby-Popper score: $\\frac{4\\pi\\cdot A}{P^2}$.  This score, which falls between 0 and 1, is often used as a measure of compactness."
      ],
      "metadata": {
        "id": "-Fujz3GD4yuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import pi\n",
        "\n",
        "4*pi*gdf.loc[0,'geometry'].area/(gdf.loc[0,'geometry'].length)**2"
      ],
      "metadata": {
        "id": "TbmsfNJg4Yho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import pi\n",
        "from shapely.ops import unary_union\n",
        "\n",
        "def PolsbyPopper(partition_col):\n",
        "  #  We start by making a dictionary of lists of polygons by district.\n",
        "  polygon_list_dict = {district: [gdf.loc[vtd,'geometry'] for vtd in gdf[gdf[partition_col] == district].index] \n",
        "                       for district in districts}\n",
        "  \n",
        "  #  We then find the union of each list of polygons to make a single polygon \n",
        "  #  for the entire district.\n",
        "  district_poly_dict = {district:unary_union(polygon_list_dict[district]) for district in districts}\n",
        "  \n",
        "  #  We find the Polsby Popper Score of each district polygon.\n",
        "  PP_dict = {district: 4*pi*district_poly_dict[district].area/(district_poly_dict[district].length)**2 for district in districts}\n",
        "  return PP_dict"
      ],
      "metadata": {
        "id": "4ZAiuReQHsOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's calculate the Polsby-Popper score for every district in our original partition."
      ],
      "metadata": {
        "id": "IgYqvsVh6Vbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PolsbyPopper('cd')"
      ],
      "metadata": {
        "id": "8FJX7DdS6TAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets calculate the Polsby-Popper scores in each partition."
      ],
      "metadata": {
        "id": "6HhBj8fZ6CI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This calculation will take ~18 minutes.\n",
        "\n",
        "PP_in_partitions = []\n",
        "for i in range(0,100):\n",
        "  clear_output()\n",
        "  print('Calculating Polsby Popper for Partition ' + str(i)+'.')\n",
        "  PP_in_partitions.append(list(PolsbyPopper('cd_'+str(i)).values()))"
      ],
      "metadata": {
        "id": "uunyzpKjP5c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot our data!"
      ],
      "metadata": {
        "id": "NQ7uRkt87WUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.xlabel('Partition Number')\n",
        "plt.ylabel('Polsby Popper')\n",
        "plt.boxplot(PP_in_partitions)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vlCU6cYSP5Pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example B - Correlation of Two Groups Across Districts\n",
        "\n",
        "Choose a pair of columns to compare. If the difference between the number of column 1 citizens and column 2 citizens is less than 10% of their average, then we will declare those groups to be similar in that district.  \n",
        "\n",
        "First we will choose two columns to compare. Then we will count the number of districts which are similar in each of our partitions.  In the end, we will have a distribution across all partitions: how often do these groups have similar representations?"
      ],
      "metadata": {
        "id": "MY7yCHPisYtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_1 = 'hisp'  # Choose a pair of columns to compare!\n",
        "col_2 = 'nonhisp'"
      ],
      "metadata": {
        "id": "sNPja-_rscjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  We create a command that sums the given column's population in each district.\n",
        "def column_pop_by_district(col, partition_col):\n",
        "  district_pop = {district:0 for district in districts}\n",
        "  for vtd in gdf.index:\n",
        "    vtd_district = gdf.loc[vtd,partition_col]\n",
        "    district_pop[vtd_district] += gdf.loc[vtd][col]\n",
        "  return district_pop\n",
        "\n",
        "#  We create a command that compares the difference between the columns' district \n",
        "#  populations against 10% of their average population.\n",
        "def is_correlated(col_1, col_2, partition_col):\n",
        "  col_1_pop = column_pop_by_district(col_1,partition_col)\n",
        "  col_2_pop = column_pop_by_district(col_2,partition_col)\n",
        "  return {district: abs(col_1_pop[district] - col_2_pop[district]) < \\\n",
        "          .1*(col_1_pop[district] + col_2_pop[district])/2 \\\n",
        "          for district in districts}\n",
        "\n",
        "#  We count the coorrelated districts.\n",
        "def num_correlated_districts(col_1, col_2, partition_col):\n",
        "  return list(is_correlated(col_1,col_2,partition_col).values()).count(True)\n"
      ],
      "metadata": {
        "id": "vZqXn6roxjrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we count the number of correlated districts in each partition. "
      ],
      "metadata": {
        "id": "oKONimW7L48A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  This will take ~24 minutes.\n",
        "num_corr_district_list = []\n",
        "for i in range(0,100):\n",
        "  clear_output()\n",
        "  print('Computing correlated districts for Partition ' + str(i) + '.')\n",
        "  num_corr_district_list.append(num_correlated_districts(col_1,col_2,'cd_'+str(i)))"
      ],
      "metadata": {
        "id": "Z-xB_-X0I4Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's plot our data. You can interpret your graph in terms of the degree in which your two groups are situated regionally in similar ways."
      ],
      "metadata": {
        "id": "SP5l9Er1SHxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.xlabel('Partition Number')\n",
        "plt.ylabel('Correlated Districts')\n",
        "plt.scatter(range(100),num_corr_district_list, s = 15, color='orangered')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7wz9Rt-eFEqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example C - Efficiency Gap\n",
        "\n",
        "Using the data found in two columns of the GeoDataFrame, the following cells calculate the efficiency gap favoring column 1.  The efficiency gap is defined to be the difference between two groups wasted votes, divided by the total number of votes from the two groups.  In each district, every vote by the losing party is wasted.  The winning party's only wasted votes are those beyond what is necessary to win the district."
      ],
      "metadata": {
        "id": "035D57vCJdne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a pair of columns to compare!\n",
        "col_1 = 'President_2020_D_Biden_general'\n",
        "col_2 = 'President_2020_R_Trump_general'"
      ],
      "metadata": {
        "id": "N4CyG782qqu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this experiment does not provide information about a presidential election, because votes are aggregated statewide, and not by district.\n",
        "\n",
        "However, we may consider presidential votes to be a proxy for the vote for a local representative. This then gives insight into how votes are wasted in single-member district elections which comprise the state, taken together."
      ],
      "metadata": {
        "id": "A8yWeshNbGTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import floor\n",
        "\n",
        "#  This counts the votes for each column's citizens in each district.\n",
        "def votes(col_1, col_2, district_col='cd', district_list = districts):\n",
        "  return {district:\n",
        "         {col_1: sum([gdf.loc[vdt,col_1] for vdt in gdf[gdf[district_col] == district].index]), \n",
        "          col_2: sum([gdf.loc[vdt,col_2] for vdt in gdf[gdf[district_col] == district].index])\n",
        "          } for district in district_list}\n",
        "\n",
        "#  We determine the number of votes necessary to have a majority.\n",
        "def votes_to_win(col_1, col_2, district_col='cd', district_list = districts):\n",
        "  votes_dict = votes(col_1,col_2,district_col,district_list)\n",
        "  return {district: floor((votes_dict[district][col_1] + votes_dict[district][col_2])/2)+1 for district in district_list }\n",
        "\n",
        "#  This calculates the number of wasted votes among each column's citizens.\n",
        "def wasted_votes(col_1, col_2, district_col = 'cd', district_list = districts):\n",
        "  votes_dict = votes(col_1, col_2, district_col,district_list)\n",
        "  to_win_dict = votes_to_win(col_1, col_2, district_col, district_list)\n",
        "  res = {col_1:0, col_2:0}\n",
        "  for district in district_list:\n",
        "    if votes_dict[district][col_1] > votes_dict[district][col_2]:\n",
        "      res[col_1] += votes_dict[district][col_1] - to_win_dict[district]\n",
        "      res[col_2] += votes_dict[district][col_2]\n",
        "    elif votes_dict[district][col_1] < votes_dict[district][col_2]:\n",
        "      res[col_1] += votes_dict[district][col_1] \n",
        "      res[col_2] += votes_dict[district][col_2] - to_win_dict[district]\n",
        "    else:\n",
        "      res[col_1] += votes_dict[district][col_1] \n",
        "      res[col_2] += votes_dict[district][col_2]\n",
        "  return res\n",
        "\n",
        "#  This calculates efficiency gap.\n",
        "def efficiency_gap(col_1, col_2, district_col = 'cd', district_list = districts):\n",
        "  total_voters = sum([gdf.loc[vtd,col_1] for vtd in gdf.index]) + \\\n",
        "  sum([gdf.loc[vtd,col_2] for vtd in gdf.index])\n",
        "  \n",
        "  wasted_dict = wasted_votes(col_1, col_2,district_col, district_list)\n",
        "\n",
        "  e_gap = (wasted_dict[col_2] - wasted_dict[col_1])/total_voters\n",
        "\n",
        "  return e_gap"
      ],
      "metadata": {
        "id": "gbjim50LWX62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the efficiency gap if the voting districts had been determined by Partition 9."
      ],
      "metadata": {
        "id": "yf2_-DwCq69n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "efficiency_gap(col_1, col_2, district_col='cd_9')"
      ],
      "metadata": {
        "id": "iGMswVdtxxu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make a list of efficiency gaps over all 100 partitions in the GeoDataFrame."
      ],
      "metadata": {
        "id": "iR34cTjurgaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This takes 2 minutes.\n",
        "efficiency_list = []\n",
        "for i in range(0,100):\n",
        "  clear_output()\n",
        "  print('Calculating efficiency gap for Partition ' + str(i) + '.')\n",
        "  efficiency_list.append(efficiency_gap(col_1, col_2, 'cd_'+str(i)))"
      ],
      "metadata": {
        "id": "q5VbJgfNsv_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot them!"
      ],
      "metadata": {
        "id": "0nA2bBQYrvQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.xlabel('Partition Number')\n",
        "plt.ylabel('Efficiency Gap')\n",
        "plt.bar(range(0,100),efficiency_list, color='blueviolet')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LlNhbAsRzSLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part II - Getting and Preparing Data\n",
        "\n",
        "Please follow [this link](https://colab.research.google.com/drive/1zckE-hLODHXvl6A_NABQjIqneyyVfLCh?usp=sharing#scrollTo=dYR8-ByOESHG) for the second part of our workshop."
      ],
      "metadata": {
        "id": "7bFWAhR03oR8"
      }
    }
  ]
}